{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80524326",
   "metadata": {},
   "source": [
    "# The Monte Hall Problem\n",
    "\n",
    "The Monty Hall problem is a famous probability puzzle based on a game show scenario. Here's an intuitive explanation:\n",
    "\n",
    "1. **Setup**: Imagine you're on a game show. There are three doors. Behind one door is a car (the prize you want), and behind the other two doors are goats.\n",
    "\n",
    "2. **Your Choice**: You pick one of the three doors, say Door 1.\n",
    "\n",
    "3. **Host's Action**: The host, who knows what's behind each door, opens one of the other two doors, say Door 3, revealing a goat. Now, you know Door 3 has a goat.\n",
    "\n",
    "4. **Decision Point**: The host then gives you a choice: stick with your original pick (Door 1) or switch to the remaining unopened door (Door 2).\n",
    "\n",
    "**Key Insight**: \n",
    "\n",
    "- **Initial Probability**: When you first pick a door, there is a 1/3 chance you picked the car and a 2/3 chance you picked a goat.\n",
    "\n",
    "- **After Host's Reveal**: The host's action of revealing a goat doesn't change the initial probabilities. It just gives you more information. If you initially picked a goat (which has a 2/3 chance), switching will always win you the car. If you initially picked the car (which has a 1/3 chance), switching will lose.\n",
    "\n",
    "Therefore, **switching doors** gives you a 2/3 chance of winning the car, while **staying** with your initial choice gives you only a 1/3 chance.\n",
    "\n",
    "So, **it's always better to switch!**\n",
    "\n",
    "The Monty Hall problem can be analyzed using Bayesian statistics to update the probabilities based on new information. Here's how it relates:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0962901",
   "metadata": {},
   "source": [
    "# Key Insight:\n",
    "\n",
    "Let's break down the key insight of the Monty Hall problem in more detail.\n",
    "\n",
    "\n",
    "#### Initial Probability:\n",
    "When you first pick a door, there are three possible scenarios:\n",
    "\n",
    "1. **You Pick the Car**: There is 1 car and 2 goats. The probability of picking the car is:\n",
    "   $$ P(\\text{Car}) = \\frac{1}{3} $$\n",
    "\n",
    "2. **You Pick a Goat**: There are 2 goats. The probability of picking a goat is:\n",
    "   $$ P(\\text{Goat}) = \\frac{2}{3} $$\n",
    "\n",
    "#### Host's Action:\n",
    "The host knows what is behind each door and always reveals a goat behind one of the two doors you did not pick. This action provides additional information.\n",
    "\n",
    "#### After Host's Reveal:\n",
    "Now, let's consider the scenarios based on whether you initially picked a car or a goat:\n",
    "\n",
    "1. **If You Initially Picked the Car (Probability 1/3)**:\n",
    "   - The host reveals one of the goats.\n",
    "   - If you switch, you will lose because the remaining door will have the other goat.\n",
    "   - Probability of winning if you stay:\n",
    "     $$ P(\\text{Win if Stay | Picked Car}) = 1 $$\n",
    "\n",
    "2. **If You Initially Picked a Goat (Probability 2/3)**:\n",
    "   - The host reveals the only remaining goat.\n",
    "   - If you switch, you will win because the remaining door will have the car.\n",
    "   - Probability of winning if you switch:\n",
    "     $$ P(\\text{Win if Switch | Picked Goat}) = 1 $$\n",
    "\n",
    "#### Updated Probabilities:\n",
    "After the host reveals a goat, the probabilities of winning by staying or switching are updated based on the initial probabilities.\n",
    "\n",
    "- **Probability of Winning if Staying**:\n",
    "  - You win if your initial choice was the car.\n",
    "  - Initial probability of picking the car was 1/3.\n",
    "  - So, the probability of winning if you stay is:\n",
    "    $$ P(\\text{Win if Stay}) = P(\\text{Car}) = \\frac{1}{3} $$\n",
    "\n",
    "- **Probability of Winning if Switching**:\n",
    "  - You win if your initial choice was a goat.\n",
    "  - Initial probability of picking a goat was 2/3.\n",
    "  - So, the probability of winning if you switch is:\n",
    "    $$ P(\\text{Win if Switch}) = P(\\text{Goat}) = \\frac{2}{3} $$\n",
    "\n",
    "### Therefore:\n",
    "- **Switching doors gives you a 2/3 chance of winning the car**, because if your initial pick was a goat (which is 2/3 of the time), switching will always win you the car.\n",
    "- **Staying with your initial choice gives you only a 1/3 chance of winning**, because if your initial pick was the car (which is 1/3 of the time), staying will win you the car.\n",
    "\n",
    "### Conclusion:\n",
    "**It's always better to switch!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fcd33e",
   "metadata": {},
   "source": [
    "# Bayesian Approach\n",
    "Bayesian statistics involves updating the probability estimate for a hypothesis as more evidence or information becomes available.\n",
    "\n",
    "1. **Prior Probabilities**:\n",
    "   Initially, you have a prior probability for each door hiding the car:\n",
    "   - $P(Car \\,|\\, Door 1) = \\frac{1}{3}$\n",
    "   - $P(Car \\,|\\, Door 2) = \\frac{1}{3}$\n",
    "   - $P(Car \\,|\\, Door 3) = \\frac{1}{3}$\n",
    "\n",
    "2. **New Information**:\n",
    "   The host opens one of the doors (say, Door 3) to reveal a goat. This action provides new information that must be considered.\n",
    "\n",
    "3. **Likelihood**:\n",
    "   The likelihood is the probability of the observed data (the host opening Door 3 and revealing a goat) under each hypothesis. The host will always choose a goat, knowing the locations of the car and goats:\n",
    "   - If the car is behind Door 1, the host could open Door 2 or Door 3. Since the host opened Door 3:\n",
    "     $$P(Host \\, opens \\, Door 3 \\,|\\, Car \\, behind \\, Door 1) = \\frac{1}{2}$$\n",
    "   - If the car is behind Door 2, the host must open Door 3:\n",
    "     $$P(Host \\, opens \\, Door 3 \\,|\\, Car \\, behind \\, Door 2) = 1$$\n",
    "   - If the car is behind Door 3, the host cannot open Door 3:\n",
    "     $$P(Host \\, opens \\, Door 3 \\,|\\, Car \\, behind \\, Door 3) = 0$$\n",
    "\n",
    "4. **Posterior Probabilities**:\n",
    "   Using Bayes' theorem, you update the probabilities based on this new information:\n",
    "   $$P(Car \\, behind \\, Door \\, i \\,|\\, Host \\, opens \\, Door \\, 3) = \\frac{P(Host \\, opens \\, Door \\, 3 \\,|\\, Car \\, behind \\, Door \\, i) \\times P(Car \\, behind \\, Door \\, i)}{P(Host \\, opens \\, Door \\, 3)}$$\n",
    "\n",
    "   The denominator, $P(Host \\, opens \\, Door \\, 3)$, is the total probability of the host opening Door 3, which normalizes the probabilities.\n",
    "\n",
    "   Let's calculate these probabilities:\n",
    "   - For Door 1:\n",
    "     $$P(Car \\, behind \\, Door \\, 1 \\,|\\, Host \\, opens \\, Door \\, 3) = \\frac{\\frac{1}{2} \\times \\frac{1}{3}}{P(Host \\, opens \\, Door \\, 3)} = \\frac{1}{6 \\times P(Host \\, opens \\, Door \\, 3)}$$\n",
    "   - For Door 2:\n",
    "     $$P(Car \\, behind \\, Door \\, 2 \\,|\\, Host \\, opens \\, Door \\, 3) = \\frac{1 \\times \\frac{1}{3}}{P(Host \\, opens \\, Door \\, 3)} = \\frac{1}{3 \\times P(Host \\, opens \\, Door \\, 3)}$$\n",
    "   - For Door 3:\n",
    "     $$P(Car \\, behind \\, Door \\, 3 \\,|\\, Host \\, opens \\, Door \\, 3) = \\frac{0 \\times \\frac{1}{3}}{P(Host \\, opens \\, Door \\, 3)} = 0$$\n",
    "\n",
    "   The denominator is the sum of these terms:\n",
    "   $$P(Host \\, opens \\, Door \\, 3) = \\frac{1}{6} + \\frac{1}{3} = \\frac{1}{6} + \\frac{2}{6} = \\frac{3}{6} = \\frac{1}{2}$$\n",
    "\n",
    "   Now, updating the probabilities:\n",
    "   - For Door 1:\n",
    "     $$P(Car \\, behind \\, Door \\, 1 \\,|\\, Host \\, opens \\, Door \\, 3) = \\frac{\\frac{1}{6}}{\\frac{1}{2}} = \\frac{1}{6} \\times 2 = \\frac{1}{3}$$\n",
    "   - For Door 2:\n",
    "     $$P(Car \\, behind \\, Door \\, 2 \\,|\\, Host \\, opens \\, Door \\, 3) = \\frac{\\frac{1}{3}}{\\frac{1}{2}} = \\frac{1}{3} \\times 2 = \\frac{2}{3}$$\n",
    "   - For Door 3:\n",
    "     $$P(Car \\, behind \\, Door \\, 3 \\,|\\, Host \\, opens \\, Door \\, 3) = 0$$\n",
    "\n",
    "### Conclusion:\n",
    "- The probability that the car is behind Door 1 (if you stay) is 1/3.\n",
    "- The probability that the car is behind Door 2 (if you switch) is 2/3.\n",
    "\n",
    "Using Bayesian reasoning, the updated probabilities confirm that switching doors increases your chance of winning from 1/3 to 2/3. This is a direct application of Bayes' theorem to update your beliefs based on new evidence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c9134f",
   "metadata": {},
   "source": [
    "# More on Bayesian Stats\n",
    "\n",
    "The Monty Hall problem can illustrate several key concepts in Bayesian statistics and decision theory. Here are some scenarios where it can come up in statistics:\n",
    "\n",
    "### 1. **Bayesian Updating**:\n",
    "   - **Concept**: Updating probabilities as new evidence is introduced.\n",
    "   - **Example**: The Monty Hall problem demonstrates how initial probabilities (priors) are updated based on the host's action (likelihood) to form new probabilities (posteriors).\n",
    "\n",
    "### 2. **Conditional Probability**:\n",
    "   - **Concept**: The probability of an event occurring given that another event has occurred.\n",
    "   - **Example**: In the Monty Hall problem, the conditional probability of winning the car given that the host has revealed a goat.\n",
    "\n",
    "### 3. **Decision Theory**:\n",
    "   - **Concept**: Making decisions under uncertainty.\n",
    "   - **Example**: The decision to switch or stay with the initial choice in the Monty Hall problem involves evaluating the expected utility of each decision.\n",
    "\n",
    "### 4. **Simpsonâ€™s Paradox**:\n",
    "   - **Concept**: A trend appears in several different groups of data but disappears or reverses when these groups are combined.\n",
    "   - **Example**: The Monty Hall problem can be used to show how individual probabilities change when combined with conditional probabilities.\n",
    "\n",
    "### 5. **Game Theory**:\n",
    "   - **Concept**: The study of mathematical models of strategic interaction among rational decision-makers.\n",
    "   - **Example**: The Monty Hall problem involves strategic decision-making where the contestant must decide whether to switch or stay to maximize their chances of winning.\n",
    "\n",
    "### Bayesian Analysis of Monty Hall in Python\n",
    "\n",
    "Here's how to use Bayesian statistics to solve the Monty Hall problem in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50e1d48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior probabilities after host reveals a goat behind Door 3:\n",
      "P(Car behind Door 1 | Host reveals Door 3) = 0.33\n",
      "P(Car behind Door 2 | Host reveals Door 3) = 0.67\n",
      "P(Car behind Door 3 | Host reveals Door 3) = 0.00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Prior probabilities\n",
    "P_car = np.array([1/3, 1/3, 1/3])  # Initial probabilities for doors 1, 2, 3\n",
    "\n",
    "# Likelihoods\n",
    "# If the host reveals Door 3, the likelihoods are:\n",
    "# P(Host reveals Door 3 | Car behind Door 1) = 1/2\n",
    "# P(Host reveals Door 3 | Car behind Door 2) = 1\n",
    "# P(Host reveals Door 3 | Car behind Door 3) = 0\n",
    "\n",
    "# Likelihood array for doors 1, 2, 3 respectively\n",
    "P_reveal_given_car = np.array([1/2, 1, 0])\n",
    "\n",
    "# Bayes' Theorem to calculate posterior probabilities\n",
    "P_car_given_reveal = (P_reveal_given_car * P_car) / np.sum(P_reveal_given_car * P_car)\n",
    "\n",
    "print(\"Posterior probabilities after host reveals a goat behind Door 3:\")\n",
    "print(f\"P(Car behind Door 1 | Host reveals Door 3) = {P_car_given_reveal[0]:.2f}\")\n",
    "print(f\"P(Car behind Door 2 | Host reveals Door 3) = {P_car_given_reveal[1]:.2f}\")\n",
    "print(f\"P(Car behind Door 3 | Host reveals Door 3) = {P_car_given_reveal[2]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f57f7b",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "1. **Prior Probabilities**: Each door initially has a 1/3 chance of hiding the car.\n",
    "2. **Likelihoods**: These are the probabilities of the host revealing a goat behind Door 3 given the car's location.\n",
    "3. **Bayes' Theorem**: This updates the prior probabilities using the likelihoods to get the posterior probabilities.\n",
    "\n",
    "By running this script, you'll see that the probability of the car being behind Door 2 is higher than Door 1 after the host reveals a goat behind Door 3, which justifies the decision to switch.\n",
    "\n",
    "### Applications in Real-World Statistics:\n",
    "1. **Medical Diagnosis**: Updating the probability of a disease based on test results.\n",
    "2. **Spam Filtering**: Updating the probability that an email is spam based on certain keywords.\n",
    "3. **Stock Market**: Updating predictions based on new financial data.\n",
    "4. **Weather Forecasting**: Updating weather predictions based on new meteorological data.\n",
    "\n",
    "The Monty Hall problem is a simplified model that helps in understanding these more complex real-world applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e7bdf1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
